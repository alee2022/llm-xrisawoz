{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c59dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ec5de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/gpt-4/dst_en_results.json\") as json_file:\n",
    "    prompts = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d4f669c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( hospital ) general_or_specialized equal_to \" general hospital \" , key_departments equal_to \" psychological department \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'( hospital ) general_or_specialized equal_to \" general hospital \" , key_departments equal_to \" psychological department \"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"( hospital ) general_or_specialized equal_to \\\" general hospital \\\" , key_departments equal_to \\\" psychological department \\\"\"\n",
    "normalize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7180bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(response):\n",
    "    if response == \"null\":\n",
    "        return response\n",
    "    idx = 0\n",
    "    while response[idx] != \")\":\n",
    "        idx += 1\n",
    "        if idx == len(response):\n",
    "            return \"null\"\n",
    "    schema = response[:idx + 1]\n",
    "    rem = response[idx + 1:]\n",
    "    tokens = rem.split(',')\n",
    "    tokens = sorted(tokens)\n",
    "    ret = schema + \",\".join(tokens)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1949c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = [\"gpt-4\", \"gpt-35-turbo\"]\n",
    "langs = [\"en\", \"enhi\", \"ko\", \"zh\", \"fr\", \"hi\"]\n",
    "subtasks = [\"dst\", \"da\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f072600",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m      9\u001b[0m     prompt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m normalize(prompt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 10\u001b[0m     prompt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(prompt)\n\u001b[1;32m     12\u001b[0m outname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults_norm/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m eng \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m sub \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m lang \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_results.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m      4\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      6\u001b[0m     idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      7\u001b[0m schema \u001b[38;5;241m=\u001b[39m response[:idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "for eng in engines:\n",
    "    for lang in langs:\n",
    "        for sub in subtasks:\n",
    "            filename = \"results_new/\" + eng + \"/\" + sub + \"_\" + lang + \"_results.json\"\n",
    "            with open(filename) as json_file:\n",
    "                prompts = json.load(json_file)\n",
    "            results = []\n",
    "            for prompt in prompts:\n",
    "                prompt[\"output\"] = normalize(prompt[\"output\"])\n",
    "                prompt[\"prediction\"] = normalize(prompt[\"prediction\"])\n",
    "                results.append(prompt)\n",
    "            outname = \"results_norm/\" + eng + \"/\" + sub + \"_\" + lang + \"_results.json\"\n",
    "            with open(outname, \"w\") as f:\n",
    "                json.dump(results, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e028be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for prompt in prompts:\n",
    "    prompt[\"output\"] = normalize(prompt[\"output\"])\n",
    "    prompt[\"prediction\"] = normalize(prompt[\"prediction\"])\n",
    "    results.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "678b099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results_norm/gpt-4/dst_en_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a788b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
